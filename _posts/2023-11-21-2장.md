# 모델에서 제품까지

본 장에서는 책을 따라 간단한 딥러닝 프로젝트를 실습해 볼 것이다.


## 데이터 수집

딥러닝을 시작하기 앞서, 모든 프로젝트의 시작은 데이터 수집이다. 
> 본인 또한 과거 인턴 경험에서 원천 데이터의 중요성 및 튜닝 과정의 중요성을 몸소 깨달았다.

이 책 저자는 '빙 이미지 분석'(Azure 서비스)를 이용해 이미지셋을 불러왔다. 간단하게 Azure서비스를 이용하기 위한 절차를 설명하자면
Azure서비스에 가입 후, 마켓플레이스에서 *Bing Search v7*을 생성한다. 학생용 무료 $100 크레딧이 있지만 필자는 안전하게 무료서비스를 이용했다.
> 본인은 'AiHub'과 'Roboflow'라는 사이트에서 프로젝트를 위한 이미지 셋을 다운하였다. 혹시나 유료결제가 걱정된다면 이를 활용하는 것을 추천한다.

이제 이 서비스를 vscode에서 활용하려면 키를 불러와야한다. 이는 aws(아마존)서비스를 이용할 때도 방법이 유사하니 이에 익숙해지는 것을 추천한다.
AWS 서비스와 달리 우린 여기서 사전에 fastbook애서 utils에 저장한 라이브러리를 불러오겠다.

---


## 패키지 설치 및 import 시키기

비록 순서상으로는 맞지 않지만, 우선 라이브러리에 대해 설명하고자 한다. Python의 가장 큰 장점이자 현재 대중적으로 활용되는데 있어서는 이 라이브러러의 범용성이 가장 크다.

```python
# 패키지 설치
pip install fastbook
pip install nbdev
```

이후 필요한 패키지를 import한다. 물론 필자는 기존 가상환경 설정에 pyTorch와 conda, Cuda 등 기본 패키지들을 사전에 설치해서 경우에 따라 다른 가상환경에서는 
추가적으로 설치가 필요한 것이 존재할 수 있다. 

```python
# 패키지 설치
import os
import glob
import fastbook
import pathlib

fastbook.setup_book()
from pathlib import Path
from fastbook import *
from fastai.vision.widgets import *
```

> os, glob, pathlib 같은 패키지들은 기본 중에 기본 라이브러리들이니 시간을 내서 document를 읽어보는 것을 추천한다.

---


다시 돌아와서, Azure에서 받은 키를 'XXX'안에 수정해서 정의해준다

> 잘 모르겠다면... [키 설정법]([https://www.markdownguide.org/cheat-sheet/](https://medium.com/@syed.sohaib/cognitive-services-creating-image-dataset-using-azures-bing-image-search-api-39802ae99644)https://medium.com/@syed.sohaib/cognitive-services-creating-image-dataset-using-azures-bing-image-search-api-39802ae99644).

```python
# 키 설정 및 사진 불러오기
key = os.environ.get('AZURE_SEARCH_KEY', '2f664a6e60414d339db2b99a3b577051')
results = search_images_bing(key, 'grizzly bear')
ims = results.attrgot('contentUrl')
len(ims)
```
    # 결과
    150
  
다시 한 번 말하지만 search_images_bing은 fastbook에서 정의된 함수이므로 이를 따로 사용하려면, 개인적으로 함수를 정의해서 사용해야 한다.
이후 search_images_bing를 이용해 설정한 키로 엑세스를 확보해 'grizzly bear'(갈색곰)에 해당하는 이미지들을 검색하는것이다. 
그리고 이를 results로 정의된 배열에 다음과 같이 저장된다.

`websearchUrl:xxx, name:xxx, thumbnailUrl:xxx, ...`

여기서 본 사진이 담겨있는 Url주소인 'contentUrl'인수만 가져와서 ims에 저장하고, 이의 개수를 알기 위해 len()함수를 이용하면 총 150개의 결과가 나옴을 알 수 있다.

```python
# 예시로 사진 하나 다운해보고 출력해보기
dest = 'images/grizzly.jpg'
download_url(ims[0], dest)

im = Image.open(dest)
im.to_thumb(128,128)
```
![](/images/bear1.png "출력 결과")

```python
# 이미지 분류해서 각 폴더에 저장
bear_types = 'grizzly','black','teddy'
path=Path('/workspaces/JHK-docker/main/bears')

#폴더명이 조회되지 않는다면 생성
if not path.exists():
    path.mkdir()

    for o in bear_types:
        dest = (path/o)
        dest.mkdir(exist_ok=True)
        results = search_images_bing(key, f'{o} bear')
        download_images(dest, urls=results.attrgot('contentUrl'))
```
다음은 bear_types에 곰의 사진을 3종류(갈색곰,흑곰,곰돌이 인형)으로 나누어 정의하였다.
이후 path에다가 이 이미지들이 어디다 저장될 지를 지정한다. 필자는 main/bears라는 폴더 내 저장되도록 환경변수를 지정하였다.


```python
# 결과 확인 및 오류 파일 삭제
fns=get_image_files(path)
failed = verify_images(fns)
failed.map(Path.unlink)
```


## DataLoaders 활용

Dataloaders란?
- fastai에서 제공하는 클래스 중 하나
- DataLoader 객체를 학습용/검증용으로 분류

여기서 잠깐...
학습용/검증용은 무엇인가? 물론 인터넷에 더 휼륭한 설명들이 많지만 필자는 본인의 해석으로 이를 설명해 보겠다.
주로 우리는 이를 Train/Valid Set이라 일컫는다. 보통은 Train/Test Set이 기본이며 Valid 데이터는 꼭 필수적인것은 아니다(물론 성능향상의 효과는 있다)

단계로 쉽게 설명하자면...

1. 학습 데이터로 이미지를 학습
2. 검증 데이터로 이가 제대로 학습되었는지 확인
3. 테스트 데이터로 예측해보기

물론 이 3개 혹은 2개의 데이터셋은 서로 겹치면 안된다. 절대적인 규칙은 아니지만 이들의 겹치면 과적합의 문제가 발생할 수 있고 혹은 이미 학습된 데이터를 검증하는, 즉 정답을 알고 문제를 푸는
것과 같이 불필요한 과정의 단계로 괜히 계산 시간만 늘리는 낭비의 과정이라 생각된다. 일단은 이렇게 간단하게 짚고만 넘어가겠다.

Dataloaders를 활용하기 위해서는 적어도 4가지의 정보를 필요로 한다.

    - 작업 데이터 유형(이미지인가 텍스트인가 등)
    - 데이터 목록을 가져오는 방법(index 불러오기)
    - 데이터 레이블 지정 방법
    - 검증용 데이터셋을 만드는 법

> 본인은 주로 index를 csv 혹은 txt파일 형식으로 따로 생성해서 이용(Retina나 Yolo 활용 편이)

```python
bears = DataBlock(
    blocks=(ImageBlock,CategoryBlock),
    get_items=get_image_files,
    splitter=RandomSplitter(valid_pct=0.2,seed=42),
    get_y=parent_label,
    item_tfms=Resize(128)
)
```

---
`blocks=(ImageBlock, CategoryBlock)`

독립변수(X)와 종속변수(Y)의 데이터 유형을 튜플(tuple)로 지정하는 부분

`get_items=get_image_files`

위에 get_images_files에 저장된 목록을 이용할 데이터 경로 목록을 가져오는 방법

`splitter=RandomSplitter(valid_pct=0.2, seed=42)`

valid_pct=0.2 -검증용 데이터셋으로 20%의 데이터들을 할당
seed=42 -난수 생성의 임의성을 고정하기위해 seed값 고정(꼭 42일 필요 X), 고정 안할 시 매번 다른 검증데이터셋 생성

`get_y=parent_label`

parent_label 함수는 fastai에서 제공하는 함수로 파일이 저장된 폴더명을 가져온다. 이를 get_y를 이용해 레이블로 지정


`item_tfms=Resize(128)`

이미지의 크기를 일정하게 맞추는 변형
>










